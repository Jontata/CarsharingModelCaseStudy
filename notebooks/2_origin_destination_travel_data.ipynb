{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Request generation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import pyrosm # type: ignore\n",
    "import osmnx as ox # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "import pandas as pd # type: ignore\n",
    "import networkx as nx # type: ignore\n",
    "import geopandas as gpd # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "from shapely.geometry import Point, LineString # type: ignore\n",
    "from typing import Tuple\n",
    "\n",
    "# Set working directory\n",
    "while os.path.basename(os.getcwd()).lower() != 'carsharingmodelcasestudy':\n",
    "    os.chdir('..')\n",
    "assert os.path.basename(os.getcwd()).lower() == 'carsharingmodelcasestudy', os.getcwd()\n",
    "\n",
    "# Load local functions\n",
    "from helpers.google_maps_api import get_transit_time\n",
    "from helpers.google_maps_api import details_from_response\n",
    "\n",
    "# Pandas settings\n",
    "pd.options.mode.chained_assignment = None  # Suppress SettingWithCopyWarning\n",
    "pd.set_option('display.max_columns', None) # Show all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "zones = gpd.read_file('data/sogn-granser-geojson.json') # zones for Public Transport (parishes are used as a proxy for DSB zones)\n",
    "stations = pd.read_csv('data/20_css_cop_latlng.csv', sep=';', index_col=0)\n",
    "od_data = pd.read_csv('requests/od_data.csv', sep=';', encoding='utf-8')\n",
    "\n",
    "# Google Maps directory and file setup\n",
    "gmaps_data_dir_rel_path = 'data/GoogleMaps/'\n",
    "gmaps_data_dir = os.path.join(os.getcwd(), gmaps_data_dir_rel_path)\n",
    "os.makedirs(gmaps_data_dir, exist_ok=True)\n",
    "gmaps_data_file = os.path.join(gmaps_data_dir, f'gmaps_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pyrosm.readthedocs.io/en/latest/graphs.html\n",
    "self = pyrosm.OSM.__init__ # Initialize the OSM object \n",
    "osm = pyrosm.OSM(\"./data/OSM/Copenhagen.osm.pbf\")\n",
    "\n",
    "# Get driving network\n",
    "drive_net = osm.get_network(network_type=\"driving\", nodes=True)\n",
    "drive_nodes, drive_edges = drive_net\n",
    "G_drive = osm.to_graph(drive_nodes, drive_edges, graph_type=\"networkx\")\n",
    "\n",
    "# Get walking network\n",
    "walk_net = osm.get_network(network_type=\"walking\", nodes=True)\n",
    "walk_nodes, walk_edges = walk_net\n",
    "G_walk = osm.to_graph(walk_nodes, walk_edges, graph_type=\"networkx\")\n",
    "\n",
    "# Get POIs\n",
    "pois = osm.get_pois()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stations_gdf():\n",
    "    stations_gdf = gpd.GeoDataFrame(stations, geometry=gpd.points_from_xy(stations['lng'], stations['lat']), crs=\"EPSG:4326\")\n",
    "    station_nodes = ox.distance.nearest_nodes(G_drive, X=stations['lng'], Y=stations['lat'])\n",
    "    stations_gdf['node'] = station_nodes\n",
    "    return stations_gdf\n",
    "\n",
    "stations_gdf = get_stations_gdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to plot stations and POIs\n",
    "def plot_stations_pois(station_points, pois_filtered):\n",
    "    # Convert to GeoDataFrame\n",
    "    pois_filtered_gdf = gpd.GeoDataFrame(pois_filtered, geometry=gpd.points_from_xy(pois_filtered['centroid_lon'], pois_filtered['centroid_lat']), crs=\"EPSG:4326\")\n",
    "    # Plot the map\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    # Plot the road network as a background\n",
    "    drive_edges.plot(ax=ax, linewidth=0.5, color=\"gray\", alpha=0.5)\n",
    "    # Plot stations with a specific color and marker\n",
    "    station_points.plot(ax=ax, color=\"blue\", marker=\"o\", markersize=50, label=\"Stations\")\n",
    "    # Plot filtered POIs with another color and marker\n",
    "    pois_filtered_gdf.plot(ax=ax, color=\"red\", marker=\"o\", markersize=10, label=\"Filtered POIs\")\n",
    "    # Add legend and title\n",
    "    plt.legend()\n",
    "    plt.title(\"Map of Stations and Filtered POIs in Copenhagen\")\n",
    "    plt.xlabel(\"Longitude\")\n",
    "    plt.ylabel(\"Latitude\")\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_request(input_point, station=stations_gdf):\n",
    "    input_point[\"centroid_lon\"] = input_point[\"origin_lon\"]\n",
    "    input_point[\"centroid_lat\"] = input_point[\"origin_lat\"]\n",
    "    input_point_od = {\n",
    "        \"origin_lon\": input_point[\"destination_lon\"].values[0],\n",
    "        \"origin_lat\": input_point[\"destination_lat\"].values[0],\n",
    "        \"centroid_lon\": input_point[\"destination_lon\"].values[0],\n",
    "        \"centroid_lat\": input_point[\"destination_lat\"].values[0]\n",
    "    }\n",
    "    input_point_formatted = pd.concat([input_point, pd.DataFrame([input_point_od])], ignore_index=True)\n",
    "    plot_stations_pois(station, input_point_formatted)\n",
    "\n",
    "\n",
    "plot_request(od_data.sample(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_zones_crossed(origin: Tuple[float, float], destination: Tuple[float, float], zones_gdf: gpd.GeoDataFrame) -> int:\n",
    "    # Create Points for origin and destination\n",
    "    origin_point = Point(origin[1], origin[0])\n",
    "    destination_point = Point(destination[1], destination[0])\n",
    "    path_line = LineString([origin_point, destination_point])\n",
    "    intersecting_zones = zones_gdf[zones_gdf.intersects(path_line)]\n",
    "    num_zones_crossed = intersecting_zones['sognekode'].nunique()  # Replace 'sognekode' with geodata from price-zones later\n",
    "    num_zones_crossed = np.ceil(num_zones_crossed/3) #! TEMP: 3 \"sogn\" equate one zone\n",
    "    return num_zones_crossed\n",
    "\n",
    "# Zone Map: https://www.dsb.dk/globalassets/pdf/trafikinformation/231201_dot_zonekort_dec_2023_print_v01.pdf\n",
    "# Price info: https://webapp.rejseplanen.dk/bin/help.exe/mn?L=vs_rkfc&tpl=prisblad\n",
    "# Price can be calcuated \n",
    "def calculate_price_zones_travelled(zone_count):\n",
    "    if zone_count <= 2:\n",
    "        return 20.5  # Fixed price for 1-2 zones\n",
    "    else:\n",
    "        return 20.5 + (zone_count - 2) * 6 # linear increase of 6 DKK starting from 3 zones\n",
    "\n",
    "def price_public_transport(customer_request: pd.Series, verbose = False) -> float:\n",
    "    \"\"\"Returns price for by public transport for a given customer request.\"\"\"\n",
    "    request_origin = (customer_request[\"origin_lat\"].values[0], customer_request[\"origin_lon\"].values[0])\n",
    "    request_destination = (customer_request[\"destination_lat\"].values[0], customer_request[\"destination_lon\"].values[0])\n",
    "    count_zones_crossed_value = count_zones_crossed(request_origin, request_destination, zones)\n",
    "    price = calculate_price_zones_travelled(count_zones_crossed_value)\n",
    "    price = price / 7.5 # convert DKK to EUR\n",
    "    if verbose:\n",
    "        print(f\"count_zones_crossed_value {count_zones_crossed_value}\")\n",
    "        print(f\"price {price}\")\n",
    "    return price\n",
    "\n",
    "test_point = od_data.sample(1)\n",
    "\n",
    "price_public_transport(test_point, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmaps_request_already_made(request_input_data_dict):\n",
    "    # Load the existing data from the file\n",
    "    try:\n",
    "        with open(gmaps_data_file, 'r') as f:\n",
    "            existing_data = json.load(f)\n",
    "            if not isinstance(existing_data, list):\n",
    "                raise ValueError(\"JSON file does not contain a list\")\n",
    "    except Exception as e:\n",
    "            print(Exception)\n",
    "            existing_data = []\n",
    "    # Check file\n",
    "    if any(d['request_input_data'] == request_input_data_dict for d in existing_data):\n",
    "        # return the existing data\n",
    "        existing_data_element = [d for d in existing_data if d['request_input_data'] == request_input_data_dict]\n",
    "        return existing_data_element\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "def append_to_gmaps_data_file(file_path, data):\n",
    "    # Check if the file exists and read its contents\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            try:\n",
    "                existing_data = json.load(f)\n",
    "                if not isinstance(existing_data, list):\n",
    "                    raise ValueError(\"JSON file does not contain a list\")\n",
    "            except json.JSONDecodeError:\n",
    "                existing_data = []\n",
    "    else:\n",
    "        existing_data = []\n",
    "    # Append the new data to the existing data\n",
    "    existing_data.append(data)\n",
    "    # Write the updated data to the file\n",
    "    with open(file_path, 'w') as f:\n",
    "        json.dump(existing_data, f)\n",
    "\n",
    "def google_maps_transit_data(customer_request, verbose = False):\n",
    "    origin_lat = customer_request['origin_lat'].values[0]\n",
    "    origin_lon = customer_request['origin_lon'].values[0]\n",
    "    destination_lat = customer_request['destination_lat'].values[0]\n",
    "    destination_lon = customer_request['destination_lon'].values[0]\n",
    "    # the departure time must be in the future, here set to 2025 01 7 12:00\n",
    "    departure_time = 1736247600 \n",
    "    request_input_data_dict = {\n",
    "        \"origin_lat\": origin_lat,\n",
    "        \"origin_lon\": origin_lon,\n",
    "        \"destination_lat\": destination_lat,\n",
    "        \"destination_lon\": destination_lon,\n",
    "        \"departure_time\": departure_time\n",
    "    }\n",
    "    gmaps_request_already_made_status = gmaps_request_already_made(request_input_data_dict)\n",
    "    if gmaps_request_already_made_status == -1:\n",
    "        print(\"requesting new google maps data\")\n",
    "        # get data from google maps\n",
    "        travel_data, raw_data = get_transit_time(origin_lat, origin_lon, destination_lat, destination_lon, departure_time)\n",
    "        # add input data to raw_data\n",
    "        raw_data['request_input_data'] = request_input_data_dict\n",
    "        # Append the data to the local file\n",
    "        append_to_gmaps_data_file(gmaps_data_file, raw_data)\n",
    "    else:\n",
    "        print(\"google maps already made\") if verbose else None\n",
    "        gmaps_request_already_made_status = gmaps_request_already_made_status[0]\n",
    "        travel_data = details_from_response(gmaps_request_already_made_status)\n",
    "    # return the travel data regardless of origin\n",
    "    return travel_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request Algorithm Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$u_{ki}=f_u(p_{i,j(k)},T^A_{o(k,i)},T^A_{j(k),d(k)},T^V_{i,j(k)};\\beta_k), \\qquad (2)$$\n",
    "$$p_{i,j(k)}=\\sum_{in\\in\\mathcal{L}}P^l\\alpha_{i,j(k),l}+T^V_{i,j(k)}P^{CS}, \\qquad \\forall i \\in\\mathcal{I}^k$$\n",
    "$$\\mathcal{R}=\\big\\{\n",
    "    k\\in\\mathcal{K} | \\exists i \\in\\mathcal{I}^k, l\\in\\mathcal{L}:u_{k,i}\\geq \\max_{m\\in\\mathcal{M}} U_{m,k}\n",
    "    \\big\\}, \\qquad (3)$$\n",
    "$$U_{mk}=\\beta^C_kP_{mk}+\\beta^V_kT^V{mk}+\\beta^A_kT^A_{mk}+\\beta^B_kT^B_{mk} \\qquad (4.2)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_between_two_nodes(origin_node, destination_node, mode=\"walking\", verbose = False) -> float:\n",
    "    try:\n",
    "        if mode == \"walking\":\n",
    "            G_mode = G_walk\n",
    "        elif mode == \"driving\":\n",
    "            G_mode = G_drive\n",
    "        else:\n",
    "            raise ValueError(\"Invalid mode\")\n",
    "        length = nx.shortest_path_length(G_mode, origin_node, destination_node, weight='length')\n",
    "        print(f\"walking distance: {length}\") if verbose else None\n",
    "        return length\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"No Path Found, Exeption: {e}\") # alternatively, length = float('inf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember customer utility function:\n",
    "$$u_{k,i,l} = \\beta^C_k(P^l+T^V_{i,j}P^{CS})+\\beta^V_kT^V_{i,j}+\\beta^A_k(T^A_{o(k),i}+T^A_{j,d(k)}), \\qquad \\forall i\\in\\mathcal{I}^k, \\forall j\\in\\mathcal{J}_k,  \\forall l\\in\\mathcal{L}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_N_stations_to_node(origin_node, N):\n",
    "    \"\"\"returns touple with station node, station coordinates and distance to the station\"\"\"\n",
    "    # Compute shortest path lengths to all reachable nodes within a reasonable threshold\n",
    "    distance_threshold = 3000  # 3 km threshold\n",
    "    lengths = nx.single_source_dijkstra_path_length(G_walk, origin_node, cutoff=distance_threshold, weight='length')\n",
    "    # Find distances to station nodes only\n",
    "    nearest_stations = []\n",
    "    for station_node in stations_gdf['node']:\n",
    "        if station_node in lengths:\n",
    "            distance = lengths[station_node]\n",
    "            nearest_stations.append((station_node, distance))\n",
    "    # Sort stations by distance and select the nearest N\n",
    "    nearest_stations.sort(key=lambda x: x[1])\n",
    "    nearest_n_stations = nearest_stations[:N]\n",
    "    # Retrieve station coordinates from the station nodes\n",
    "    result = []\n",
    "    for station_node, distance in nearest_n_stations:\n",
    "        station_details = stations_gdf.loc[stations_gdf['node'] == station_node].iloc[0]\n",
    "        result.append([station_node, (station_details['lat'], station_details['lng']), distance])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the utility of the car-sharing service customer\n",
    "def calculate_CS_travel_data(customer_request: pd.Series, _station_origin_node, _station_destination_node, verbose = False) -> Tuple[float, float, float]:\n",
    "    \"\"\"returns time: OS -> Driving -> SD times\"\"\"\n",
    "    origin_node = customer_request['origin_node'].values[0]\n",
    "    dest_node = customer_request['destination_node'].values[0]\n",
    "    walking_dist_from_origin_to_station = distance_between_two_nodes(origin_node, _station_origin_node, \"walking\", verbose)\n",
    "    request_driving_dist = distance_between_two_nodes(_station_origin_node, _station_destination_node, \"driving\", verbose)\n",
    "    walking_dist_from_station_to_destination = distance_between_two_nodes(_station_destination_node, dest_node, \"walking\", verbose)\n",
    "    CS_data_tuple = (walking_dist_from_origin_to_station, request_driving_dist, walking_dist_from_station_to_destination)\n",
    "    print(f\"CS dists: {CS_data_tuple}\") if verbose else None\n",
    "    return CS_data_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_origin_destination_nodes_to_row_item(row):\n",
    "    origin_lat = row['origin_lat']\n",
    "    origin_lon = row['origin_lon']\n",
    "    destination_lat = row['destination_lat']\n",
    "    destination_lon = row['destination_lon']\n",
    "    origin_node = ox.distance.nearest_nodes(G_walk, X=origin_lon, Y=origin_lat)\n",
    "    destination_node = ox.distance.nearest_nodes(G_walk, X=destination_lon, Y=destination_lat)\n",
    "    row['origin_node'] = origin_node\n",
    "    row['destination_node'] = destination_node\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_single_request_row(potential_customer_k, verbose = False, csv_file='./requests/od_travel_data_revised.csv'):\n",
    "    try:\n",
    "        with open(csv_file, mode='x', newline='') as file:\n",
    "            writer = csv.writer(file, delimiter=';')\n",
    "            writer.writerow(['request_id', 'origin_node', 'destination_node', 'alternative_transportation_data', \n",
    "                             'i_stations', 'j_stations', 'cs_travel_data'])\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "\n",
    "    request_id = potential_customer_k.index[0]\n",
    "    origin_node = potential_customer_k['origin_node'].values[0]\n",
    "    destination_node = potential_customer_k['destination_node'].values[0]\n",
    "    \n",
    "    # For alternative transportation methods\n",
    "    walking_distance_value = distance_between_two_nodes(origin_node, destination_node, \"walking\", verbose) # Used for utility calculations\n",
    "    public_travel_price = price_public_transport(potential_customer_k, verbose)\n",
    "    google_maps_data_obj = google_maps_transit_data(potential_customer_k, verbose)\n",
    "    total_duration_minutes, access_time_minutes, transfer_times_minutes_sum = google_maps_data_obj['total_duration_minutes'], google_maps_data_obj['access_time_minutes'], sum(google_maps_data_obj['transfer_times_minutes'])\n",
    "    alternative_transportation_data = {\n",
    "        'walking_distance_value': walking_distance_value,\n",
    "        'public_travel_price': public_travel_price,\n",
    "        'public_travel_time': total_duration_minutes,\n",
    "        'public_travel_access_time': access_time_minutes,\n",
    "        'public_travel_transfer_time': transfer_times_minutes_sum\n",
    "    }\n",
    "\n",
    "    # For CS service\n",
    "    i_stations = nearest_N_stations_to_node(origin_node, 3)\n",
    "    j_stations = nearest_N_stations_to_node(destination_node, 3)\n",
    "\n",
    "    cs_travel_data = {}\n",
    "\n",
    "    for i_idx, i_station in enumerate(i_stations):\n",
    "        for j_idx, j_station in enumerate(j_stations):\n",
    "            walk1, drive, walk2 = calculate_CS_travel_data(potential_customer_k,\n",
    "                                                        i_station[0],\n",
    "                                                        j_station[0],\n",
    "                                                        verbose)\n",
    "            cs_travel_data[(i_idx, j_idx)] = (walk1, drive, walk2)\n",
    "\n",
    "    with open(csv_file, mode='a', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file, delimiter=';')\n",
    "        writer.writerow([\n",
    "            request_id, origin_node, destination_node, alternative_transportation_data, i_stations, j_stations,\n",
    "            cs_travel_data,\n",
    "        ])\n",
    "\n",
    "def preprocess_requests(requests, verbose = False):\n",
    "    for r_idx in range(requests.shape[0]):\n",
    "        potential_customer_k = requests.iloc[[r_idx]]\n",
    "        origin_lat, origin_lon = potential_customer_k['origin_lat'].values[0], potential_customer_k['origin_lon'].values[0]\n",
    "        destination_lat, destination_lon = potential_customer_k['destination_lat'].values[0], potential_customer_k['destination_lon'].values[0]\n",
    "        print(f\"Processing request {r_idx} from {origin_lat}, {origin_lon} to {destination_lat}, {destination_lon}\")\n",
    "        potential_customer_k = potential_customer_k.apply(append_origin_destination_nodes_to_row_item, axis=1)\n",
    "        preprocess_single_request_row(potential_customer_k, verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess requests and save to file\n",
    "preprocess_requests(od_data, verbose=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
